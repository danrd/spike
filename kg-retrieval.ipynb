{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%pip install -U sentence-transformers\n%pip install hnswlib\n%pip install SPARQLWrapper\n%pip install rdflib\n%pip install spacy\n# python -m spacy download en_core_web_sm","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:22:32.412556Z","iopub.execute_input":"2023-10-04T10:22:32.412935Z","iopub.status.idle":"2023-10-04T10:23:59.394954Z","shell.execute_reply.started":"2023-10-04T10:22:32.412885Z","shell.execute_reply":"2023-10-04T10:23:59.393774Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting sentence-transformers\n  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.33.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.66.1)\nRequirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (2.0.0+cpu)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.15.1+cpu)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.23.5)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.11.2)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (3.2.4)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.1.99)\nRequirement already satisfied: huggingface-hub>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.16.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.12.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.9.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.31.0)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.6.3)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (21.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2023.6.3)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.13.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.3.3)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk->sentence-transformers) (1.16.0)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.1.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->sentence-transformers) (9.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers) (3.0.9)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2023.7.22)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\nBuilding wheels for collected packages: sentence-transformers\n  Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125926 sha256=7a3f23e6462c7a6dca3d30dd70ca0b20330d234781313cf1685bfa5da2b32128\n  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\nSuccessfully built sentence-transformers\nInstalling collected packages: sentence-transformers\nSuccessfully installed sentence-transformers-2.2.2\nNote: you may need to restart the kernel to use updated packages.\nCollecting hnswlib\n  Downloading hnswlib-0.7.0.tar.gz (33 kB)\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from hnswlib) (1.23.5)\nBuilding wheels for collected packages: hnswlib\n  Building wheel for hnswlib (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for hnswlib: filename=hnswlib-0.7.0-cp310-cp310-linux_x86_64.whl size=186623 sha256=707ac14a3c95963270e52835f15eab62dc4cc80b09e046699fca17a291a43018\n  Stored in directory: /root/.cache/pip/wheels/8a/ae/ec/235a682e0041fbaeee389843670581ec6c66872db856dfa9a4\nSuccessfully built hnswlib\nInstalling collected packages: hnswlib\nSuccessfully installed hnswlib-0.7.0\nNote: you may need to restart the kernel to use updated packages.\nCollecting SPARQLWrapper\n  Downloading SPARQLWrapper-2.0.0-py3-none-any.whl (28 kB)\nCollecting rdflib>=6.1.1 (from SPARQLWrapper)\n  Downloading rdflib-7.0.0-py3-none-any.whl (531 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m531.9/531.9 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting isodate<0.7.0,>=0.6.0 (from rdflib>=6.1.1->SPARQLWrapper)\n  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: pyparsing<4,>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from rdflib>=6.1.1->SPARQLWrapper) (3.0.9)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from isodate<0.7.0,>=0.6.0->rdflib>=6.1.1->SPARQLWrapper) (1.16.0)\nInstalling collected packages: isodate, rdflib, SPARQLWrapper\nSuccessfully installed SPARQLWrapper-2.0.0 isodate-0.6.1 rdflib-7.0.0\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: rdflib in /opt/conda/lib/python3.10/site-packages (7.0.0)\nRequirement already satisfied: isodate<0.7.0,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from rdflib) (0.6.1)\nRequirement already satisfied: pyparsing<4,>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from rdflib) (3.0.9)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from isodate<0.7.0,>=0.6.0->rdflib) (1.16.0)\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: spacy in /opt/conda/lib/python3.10/site-packages (3.6.1)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.0.4)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.0.9)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.0.7)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.0.8)\nRequirement already satisfied: thinc<8.2.0,>=8.1.8 in /opt/conda/lib/python3.10/site-packages (from spacy) (8.1.12)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.1.2)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.4.7)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.0.9)\nRequirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (0.9.0)\nRequirement already satisfied: pathy>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (0.10.2)\nRequirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from spacy) (6.3.0)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (4.66.1)\nRequirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.23.5)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.31.0)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.10.9)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.1.2)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy) (68.0.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (21.3)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.3.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->spacy) (3.0.9)\nRequirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.6.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.7.22)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.10)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.1.1)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy) (2.1.3)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport re\nimport sys\nimport hnswlib\nimport pickle\nimport rdflib\nimport SPARQLWrapper\nimport numpy as np\nimport pandas as pd\nimport spacy\nfrom io import StringIO\nfrom rdflib import Graph\nfrom SPARQLWrapper import SPARQLWrapper, JSON, RDF, XML \nfrom sentence_transformers import SentenceTransformer, util\n\nmodel = SentenceTransformer('all-MiniLM-L12-v2')\nnlp = spacy.load(\"en_core_web_sm\")\nstopwords = nlp.Defaults.stop_words\n\ndata_path = os.getcwd()+'\\\\data\\'","metadata":{"execution":{"iopub.status.busy":"2023-10-04T11:14:17.675771Z","iopub.execute_input":"2023-10-04T11:14:17.676280Z","iopub.status.idle":"2023-10-04T11:14:19.025822Z","shell.execute_reply.started":"2023-10-04T11:14:17.676246Z","shell.execute_reply":"2023-10-04T11:14:19.025053Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"with open(os.path.join(data_path, 'id2pred.pickle'), \"rb\") as input_file:\n    id2pred = pickle.load(input_file) \n    \nwith open(os.path.join(data_path, 'pred2id.pickle'), \"rb\") as input_file:\n    pred2id = pickle.load(input_file)    \n    \nwith open(os.path.join(data_path, 'pred2emb.pickle'), \"rb\") as input_file:\n    pred2emb = pickle.load(input_file)  \n\nwith open(os.path.join(data_path, 'id2res.pickle'), \"rb\") as input_file:\n    id2res = pickle.load(input_file)\n    \n# with open(os.path.join(data_path, 'res2id.pickle'), \"rb\") as input_file:\n#     res2id = pickle.load(input_file)    \n\n# with open(os.path.join(data_path, 'res2emb.pickle'), \"rb\") as input_file:   \n#     res2emb = pickle.load(input_file)\n\nwith open(os.path.join(data_path, 'contrib2emb.pickle'), \"rb\") as input_file: \n    contrib2emb = pickle.load(input_file) \n\nwith open(os.path.join(data_path, 'contrib2id.pickle'), \"rb\") as input_file: \n    contrib2id = pickle.load(input_file)\n\nwith open(os.path.join(data_path, 'contrib2emb.pickle'), \"rb\") as input_file:    \n    contrib2emb = pickle.load(input_file)    \n    \n      \nwith open(os.path.join(data_path, 'id2paper.pickle'), \"rb\") as input_file:     \n    id2paper = pickle.load(input_file)\n    \nwith open(os.path.join(data_path, 'paper2id.pickle'), \"rb\") as input_file: \n    paper2id = pickle.load(input_file)    \n    \nwith open(os.path.join(data_path, 'paper2emb.pickle'), \"rb\") as input_file:    \n    paper2emb = pickle.load(input_file)\n    \n\nwith open(os.path.join(data_path, 'pred_index.pickle'), \"rb\") as input_file:     \n    pred_index = pickle.load(input_file) \n\n# with open(os.path.join(data_path, 'res_index.pickle'), \"rb\") as input_file:    \n#     res_index = pickle.load(input_file)  \n\nwith open(os.path.join(data_path, 'contrib_index.pickle'), \"rb\") as input_file:    \n    contrib_index = pickle.load(input_file)     \n\nwith open(os.path.join(data_path, 'paper_index.pickle'), \"rb\") as input_file: \n    paper_index = pickle.load(input_file)    ","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:24:22.621686Z","iopub.execute_input":"2023-10-04T10:24:22.622154Z","iopub.status.idle":"2023-10-04T10:24:22.629609Z","shell.execute_reply.started":"2023-10-04T10:24:22.622111Z","shell.execute_reply":"2023-10-04T10:24:22.628005Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def filter_q(question:str):\n    \"\"\"\n    filter out unnecessary words from a question\n    \"\"\"\n    res = []\n    tok_pos = []\n    for token in nlp(question):\n        tok_pos.append((token.lemma_, token.pos_))\n        if token.pos_ in [\"NOUN\", \"PROPN\", \"ADJ\", \"VERB\"]: # keep only nouns, adjectives and verbs\n            if token.lemma_ not in stopwords:\n                res.append(str(token))\n    return \" \".join(res)\n\ndef create_n_grams(sentence, n=2):\n    \"\"\"\n    create n_grams for a sentence after its filtering\n    \"\"\"\n    filtered_sentence = filter_q(sentence)\n    words = filtered_sentence.split(\" \")\n    n_grams = []\n    text_l = len(words)\n    for i in range(2, n+1):\n        for j in range(text_l-i):\n            n_gram = words[j:j+i]\n            n_gram_text = \" \".join(n_gram)\n            n_grams.append(n_gram_text)\n    return n_grams\n\ndef set_prefixes(graph, prefixes=[]):\n    \"\"\"\n    set all prefixes from a list for a graph\n    \"\"\"\n    for prefix in prefixes:\n        graph.bind(prefix[0], prefix[1])","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:24:32.092631Z","iopub.execute_input":"2023-10-04T10:24:32.092947Z","iopub.status.idle":"2023-10-04T10:24:32.102407Z","shell.execute_reply.started":"2023-10-04T10:24:32.092887Z","shell.execute_reply":"2023-10-04T10:24:32.101136Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def n_closest(question, source, n, n_gram):\n    \"\"\"\n    return n elements of orkg relevant for a question\n    \"\"\"\n    if n_gram:\n        filteted_text = filter_q(question)\n        texts = create_n_grams(filteted_text)\n    else:\n        texts = [filter_q(question)]\n    if source==\"pred\":\n        tuples = []\n        for text in texts:\n            out, scores = pred_index.knn_query(model.encode(text, show_progress_bar=False), k=n)\n            tuples.extend(list(zip(out[0], scores[0])))\n        sorted_out = sort_tuples(tuples)[0:n]\n        all_preds = list(pred2emb.keys())\n        output = [all_preds[pair[0]] for pair in sorted_out]\n        return output\n    elif source==\"res\":\n        tuples = []\n        for text in texts:\n            out, scores = res_index.knn_query(model.encode(text, show_progress_bar=False), k=n)\n            tuples.extend(list(zip(out[0], scores[0])))\n        sorted_out = sort_tuples(tuples)[0:n]\n        all_res = list(res2emb.keys())\n        output = [all_res[pair[0]] for pair in sorted_out]\n        return output\n    elif source==\"paper\":\n        tuples = []\n        for text in texts:\n            out, scores = paper_index.knn_query(model.encode(text, show_progress_bar=False), k=n)\n            tuples.extend(list(zip(out[0], scores[0])))\n        sorted_out = sort_tuples(tuples)[0:n]\n        all_papers = list(paper2emb.keys())\n        papers = [all_papers[pair[0]] for pair in sorted_out]\n        output = [str(uri) for uri in papers]\n        return output\n    elif source==\"contrib\":\n        tuples = []\n        for text in texts:\n            out, scores = contrib_index.knn_query(model.encode(text, show_progress_bar=False), k=n)\n            tuples.extend(list(zip(out[0], scores[0])))\n        sorted_out = sort_tuples(tuples)[0:n]\n        all_contribs = list(contrib2emb.keys())\n        contribs = [all_contribs[pair[0]] for pair in sorted_out]\n        output = [str(uri) for uri in contribs]\n        return output\n    \ndef sort_tuples(l):\n    out = []\n    black_list = []\n    tuples = sorted(l, key=lambda x: x[1], reverse=False)\n    for tup in tuples:\n        if tup[0] in black_list:\n            continue\n        else:\n            out.append(tup)\n            black_list.append(tup[0])\n    return out","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:24:32.104067Z","iopub.execute_input":"2023-10-04T10:24:32.104613Z","iopub.status.idle":"2023-10-04T10:24:32.137616Z","shell.execute_reply.started":"2023-10-04T10:24:32.104575Z","shell.execute_reply":"2023-10-04T10:24:32.136714Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def construct_subgraph(triples=[], predicates_list=[]):\n    \"\"\"\n    return a graph for a list of triples\n    \"\"\"\n    res_graph = Graph()\n    set_prefixes(res_graph, prefixes)\n    for ind, triple in enumerate(triples):\n        pred_id = str(triple[1]).split(\"/\")[-1]\n        try:\n            pred = id2pred[pred_id]\n        except Exception as e:\n            continue\n        if pred not in predicates_list:\n            continue\n        else:\n            text_triple = swap_prefixes(triple)\n            res_graph.add(text_triple) \n    return res_graph\n\ndef get_subgraph_string(graph):\n    \"\"\"\n    return string representation of a graph\n    \"\"\"\n    tmp = sys.stdout\n    my_result = StringIO()\n    sys.stdout = my_result\n    graph.print()\n    sys.stdout = tmp\n    res = my_result.getvalue()\n    my_result.close()\n    return res\n\ndef swap_prefixes(triple):\n    \"\"\"\n    replace ids in a triple with textual representation\n    \"\"\"\n    subj_id = str(triple[0]).split(\"/\")[-1]\n    subj_base = str(triple[0]).split(\"/\")[0:-1]\n    if subj_id in id2res.keys():\n        subj = re.sub(r\"[^a-zA-Z\\d]+\", \"_\", id2res[subj_id])\n        subj_base.append(subj)\n        triple[0] = rdflib.term.URIRef(\"/\".join(subj_base))\n    \n    pred_id = str(triple[1]).split(\"/\")[-1]\n    pred_base = str(triple[1]).split(\"/\")[0:-1]\n    if pred_id in id2pred.keys():\n        pred = re.sub(r\"[^a-zA-Z\\d]+\", \"_\", id2pred[pred_id])\n        pred_base.append(pred)\n        triple[1] = rdflib.term.URIRef(\"/\".join(pred_base))\n    \n    obj_id = str(triple[2]).split(\"/\")[-1]\n    obj_base = str(triple[2]).split(\"/\")[0:-1]\n    if obj_id in id2res.keys():\n        obj = re.sub(r\"[^a-zA-Z\\d]+\", \"_\", id2res[obj_id])\n        obj_base.append(obj)\n        triple[2] = rdflib.term.URIRef(\"/\".join(obj_base))\n    return triple    ","metadata":{"execution":{"iopub.status.busy":"2023-10-04T12:22:09.310783Z","iopub.execute_input":"2023-10-04T12:22:09.311247Z","iopub.status.idle":"2023-10-04T12:22:09.323841Z","shell.execute_reply.started":"2023-10-04T12:22:09.311215Z","shell.execute_reply":"2023-10-04T12:22:09.323000Z"},"trusted":true},"execution_count":141,"outputs":[]},{"cell_type":"code","source":"def process_paper(paper_title, predicates_list, graph):\n    \"\"\"\n    return a subgraph of orkg for a paper using only relevant predicates\n    \"\"\"\n    paper_id = paper2id[paper_title]\n    left = '{'\n    right = '}'\n    middle = f'orkgr:{paper_id} ?x ?y. ?y ?pred ?label'\n    template = f'PREFIX orkgp: <http://orkg.org/orkg/predicate/> PREFIX orkgc: <http://orkg.org/orkg/class/> PREFIX orkgr: <http://orkg.org/orkg/resource/> SELECT ?pred ?label WHERE {left}{middle}{right}'\n    try:\n        result = graph.query(template)\n        triples = []\n        for triple in result:\n            triples.append([rdflib.term.URIRef(f'http://orkg.org/orkg/resource/{paper_id }'), triple[0], triple[1]])\n        graph = construct_subgraph(triples, predicates_list)\n        return graph\n    except Exception:\n        return Graph()\n\ndef process_contrib(contrib_title, predicates_list, graph):\n    \"\"\"\n    return a subgraph of orkg for a contribution using only relevant predicates\n    \"\"\"\n    contrib_id = contrib2id[contrib_title]\n    left = '{'\n    right = '}'\n    middle = f'orkgr:{contrib_id} ?x ?y'\n    template = f'PREFIX orkgp: <http://orkg.org/orkg/predicate/> PREFIX orkgc: <http://orkg.org/orkg/class/> PREFIX orkgr: <http://orkg.org/orkg/resource/> SELECT ?x ?y WHERE {left}{middle}{right}'\n    try:\n        result = graph.query(template)\n        triples = []\n        for triple in result:\n            triples.append([rdflib.term.URIRef(f'http://orkg.org/orkg/resource/{contrib_id }'), triple[0], triple[1]])\n        graph = construct_subgraph(triples, predicates_list)\n        return graph\n    except Exception:\n        return Graph()\n\ndef graph_text_postprocessing(graph_text:str):\n    \"\"\"\n    postprocess to improve graph serialization\n    \"\"\"\n    postprocessed_graph = graph_text.replace(\"\\n\", \"\").replace(\"  \", \"\").replace(\" .\", \". \").replace(\" ;\", \"; \").replace(\",\", \", \")  \n    return postprocessed_graph\n\ndef merge_subgraphs(subgraphs_list):\n    for idx, subgraph in enumerate(subgraphs_list):\n        if idx==0:\n            res_graph = subgraph\n        else:\n            res_graph += subgraph\n    try:\n        graph_text = get_subgraph_string(res_graph) \n        graph_text_postprocessed = graph_text_postprocessing(graph_text)\n        return graph_text_postprocessed\n    except Exception:\n        return ''","metadata":{"execution":{"iopub.status.busy":"2023-10-04T13:10:49.715813Z","iopub.execute_input":"2023-10-04T13:10:49.716838Z","iopub.status.idle":"2023-10-04T13:10:49.727736Z","shell.execute_reply.started":"2023-10-04T13:10:49.716797Z","shell.execute_reply":"2023-10-04T13:10:49.727128Z"},"trusted":true},"execution_count":199,"outputs":[]},{"cell_type":"code","source":"orkg = Graph()\norkg.parse(os.path.join(data_path, 'rdf-export-orkg.nt'))\nprefixes = [\n['orkgp', 'http://orkg.org/orkg/predicate/'],\n['orkgc', 'http://orkg.org/orkg/class/'],\n['orkgr', 'http://orkg.org/orkg/resource/'],\n['rdfs', 'http://www.w3.org/2000/01/rdf-schema#>'],\n['rdf', 'http://www.w3.org/1999/02/22-rdf-syntax-ns#'],\n['xsd', 'http://www.w3.org/2001/XMLSchema#']   \n]\nset_prefixes(orkg, prefixes)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:24:32.185843Z","iopub.execute_input":"2023-10-04T10:24:32.186318Z","iopub.status.idle":"2023-10-04T10:24:32.203835Z","shell.execute_reply.started":"2023-10-04T10:24:32.186280Z","shell.execute_reply":"2023-10-04T10:24:32.202677Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def retrieve_subgraph(question:str, main_graph:rdflib.Graph, n_preds:int=1000, n_papers:int=10, n_contribs:int=10):\n    \"\"\"\n    return a number of orkg subrgraphs related to a question\n    \"\"\"\n    subgraphs = []\n    predicates_list = n_closest(question, 'pred', n_preds, True)\n    papers_list = n_closest(question, 'paper', n_papers, True)\n    contribs_list = n_closest(question, 'contrib', n_contribs, True)\n    for paper in papers_list:\n        graph = process_paper(paper, predicates_list, main_graph)\n        if len(graph) > 0:\n            subgraphs.append(graph) \n    for contrib in contribs_list:\n        graph = process_contrib(contrib, predicates_list, main_graph)\n        if len(graph) > 0:\n            subgraphs.append(graph) \n    res_graph = merge_subgraphs(subgraphs)\n    return res_graph","metadata":{"execution":{"iopub.status.busy":"2023-10-04T11:11:54.922161Z","iopub.execute_input":"2023-10-04T11:11:54.922585Z","iopub.status.idle":"2023-10-04T11:11:54.929421Z","shell.execute_reply.started":"2023-10-04T11:11:54.922551Z","shell.execute_reply":"2023-10-04T11:11:54.928632Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"q1 = \"Which model has achieved the highest Accuracy score on the Story Cloze Test benchmark dataset?\"\nq2 = \"List the title and ID of research papers that contain a benchmark over the Penn Treebank (Word Level) dataset?\"\nq3 = \"What models are being evaluated on the UrbanSound8k dataset?\"\nq4 = \"Provide a list of research paper titles and IDs that have benchmarked models on the Penn Treebank dataset?\"\nq5 = \"What models are being evaluated on the TDMSci dataset?\"\nq6 = \"What is the mean capacity of a carbon-based fuel?\"\nq7 = \"Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the MLDoc Zero-Shot English-to-Russian dataset?\"\nq8 = \"Indicate the model that performed best in terms of Accuracy metric on the Kuzushiji-MNIST benchmark dataset?\"\nq9 = \"Which model has achieved the highest BLEU score score on the WMT2016 Romanian-English benchmark dataset?\"\nq10 = \"What is the highest benchmark result achieved on the Ball in cup, catch (DMControl500k) dataset, including the metric and its value?\"","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:22.568311Z","iopub.execute_input":"2023-10-04T10:26:22.568829Z","iopub.status.idle":"2023-10-04T10:26:22.584321Z","shell.execute_reply.started":"2023-10-04T10:26:22.568799Z","shell.execute_reply":"2023-10-04T10:26:22.583273Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"q1","metadata":{"execution":{"iopub.status.busy":"2023-10-04T14:12:11.985645Z","iopub.execute_input":"2023-10-04T14:12:11.986103Z","iopub.status.idle":"2023-10-04T14:12:11.991991Z","shell.execute_reply.started":"2023-10-04T14:12:11.986067Z","shell.execute_reply":"2023-10-04T14:12:11.990940Z"},"trusted":true},"execution_count":214,"outputs":[{"execution_count":214,"output_type":"execute_result","data":{"text/plain":"'Which model has achieved the highest Accuracy score on the Story Cloze Test benchmark dataset?'"},"metadata":{}}]},{"cell_type":"code","source":"retrieve_subgraph(q1, orkg)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T14:12:13.160424Z","iopub.execute_input":"2023-10-04T14:12:13.160840Z","iopub.status.idle":"2023-10-04T14:12:14.091549Z","shell.execute_reply.started":"2023-10-04T14:12:13.160800Z","shell.execute_reply":"2023-10-04T14:12:14.090969Z"},"trusted":true},"execution_count":215,"outputs":[{"execution_count":215,"output_type":"execute_result","data":{"text/plain":"'@prefix orkgp: <http://orkg.org/orkg/predicate/>. @prefix orkgr: <http://orkg.org/orkg/resource/>. @prefix xsd: <http://www.w3.org/2001/XMLSchema#>. orkgr:A_Simple_and_Effective_Approach_to_the_Story_Cloze_Test orkgp:Benchmark orkgr:Benchmark_Story_Cloze_Test; orkgp:model orkgr:Val_ls_skip. orkgr:A_benchmarking_method_for_information_systems orkgp:description \"Covers design tools,  software metrics,  testing and debugging,  programming environments,  etc\"^^xsd:string. orkgr:Automatic_Diagnosis_of_Attention_Deficit_Hyperactivity_Disorder_Using_Machine_Learning orkgp:contribution orkgr:Decision_tree, orkgr:K_nearest_Neighbour, orkgr:Naive_Bayes, orkgr:Random_forest, orkgr:Support_vector_machine, orkgr:logistic_regression. orkgr:Collaboration_of_Experts_Achieving_80_Top_1_Accuracy_on_ImageNet_with_100M_FLOPs orkgp:Benchmark orkgr:Benchmark_ImageNet; orkgp:model orkgr:Coe_large_194_mflops, orkgr:Coe_large_214_mflops, orkgr:Coe_small_100_mflops. orkgr:Contribution_1 orkgp:Algorithm_s_ orkgr:NSGA_II_NSGA_II; orkgp:Number_of_Objectives \"2\"^^xsd:string; orkgp:Quality_Indicators orkgr:_. orkgr:International_Phyical_Performance_Test_Profile_IPPTP_ orkgp:Standard_deviation 0.363988071680069; orkgp:test_year 1988. orkgr:Record_Identifier_14311001 orkgp:Standard_deviation 0.363988071680069; orkgp:test_year 1988. orkgr:Record_Identifier_14311201 orkgp:Standard_deviation 0.300661206245422; orkgp:test_year 1988. orkgr:Soft_Truncation_A_Universal_Training_Technique_of_Score_based_Diffusion_Model_for_High_Precision_Score_Estimation orkgp:Benchmark orkgr:Benchmark_CIFAR_10, orkgr:Benchmark_CelebA_64x64, orkgr:Benchmark_CelebA_HQ_256x256, orkgr:Benchmark_FFHQ_256_x_256, orkgr:Benchmark_ImageNet_32x32, orkgr:Benchmark_LSUN_Bedroom_256_x_256, orkgr:Benchmark_STL_10; orkgp:model orkgr:Ddpm_vp_fid_st, orkgr:Ddpm_vp_nll_st, orkgr:Udm_rve_st, orkgr:Uncsn_rve_st. orkgr:Towards_Better_Accuracy_efficiency_Trade_offs_Divide_and_Co_training orkgp:Benchmark orkgr:Benchmark_CIFAR_10, orkgr:Benchmark_CIFAR_100, orkgr:Benchmark_ImageNet; orkgp:model orkgr:Densenet_bc_190_s_4, orkgr:Pyramidnet_272_s_4, orkgr:Resnext_101_64x4d_s_2_224px, orkgr:Se_resnext_101_64x4d_s_2_416px, orkgr:Shake_shake_26_2x96d_s_4, orkgr:Wrn_28_10_s_4, orkgr:Wrn_40_10_s_4. orkgr:_International_Phyical_Performance_Test_Profile_IPPTP_ orkgp:Standard_deviation 0.300661206245422; orkgp:test_year 1988. '"},"metadata":{}}]},{"cell_type":"code","source":"q2","metadata":{"execution":{"iopub.status.busy":"2023-10-04T14:12:16.149058Z","iopub.execute_input":"2023-10-04T14:12:16.149440Z","iopub.status.idle":"2023-10-04T14:12:16.155132Z","shell.execute_reply.started":"2023-10-04T14:12:16.149410Z","shell.execute_reply":"2023-10-04T14:12:16.154436Z"},"trusted":true},"execution_count":216,"outputs":[{"execution_count":216,"output_type":"execute_result","data":{"text/plain":"'List the title and ID of research papers that contain a benchmark over the Penn Treebank (Word Level) dataset?'"},"metadata":{}}]},{"cell_type":"code","source":"retrieve_subgraph(q2, orkg)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T14:12:17.380302Z","iopub.execute_input":"2023-10-04T14:12:17.380990Z","iopub.status.idle":"2023-10-04T14:12:18.541483Z","shell.execute_reply.started":"2023-10-04T14:12:17.380954Z","shell.execute_reply":"2023-10-04T14:12:18.540725Z"},"trusted":true},"execution_count":217,"outputs":[{"execution_count":217,"output_type":"execute_result","data":{"text/plain":"'@prefix orkgp: <http://orkg.org/orkg/predicate/>. @prefix orkgr: <http://orkg.org/orkg/resource/>. @prefix xsd: <http://www.w3.org/2001/XMLSchema#>. orkgr:A_benchmarking_method_for_information_systems orkgp:Data_analysis orkgr:analysis; orkgp:description \"Covers design tools,  software metrics,  testing and debugging,  programming environments,  etc\"^^xsd:string; orkgp:research_paradigm orkgr:exploratory; orkgp:research_problem orkgr:empirical_research_in_requirements_engineering; orkgp:research_question_ orkgr:Research_Questions_in_RE_Contribution; orkgp:research_question_answer orkgr:hidden_in_text. orkgr:Bio_ID_track_overview orkgp:Best_score \"0.65 micro-F1 for normalized cell type\"^^xsd:string, \"0.76 micro-F1 for normalized species\"^^xsd:string, \"0.8 or better for cell type,  species and gene-or-protein at mention-level F1\"^^xsd:string, \"below 0.6 micro-F1 for other normalized entity types\"^^xsd:string; orkgp:Evaluation_metrics orkgr:F1, orkgr:Precision, orkgr:Recall; orkgp:description \"The task is to annotate text from figure legends with the entity types and IDs for taxon (organism),  gene,  protein,  miRNA,  small molecules,  cellular components,  cell types and cell lines,  tissues and organs.\"^^xsd:string; orkgp:number_of_papers \"196 full length articles as test data\"^^xsd:string, \"570 full length articles as training data\"^^xsd:string; orkgp:research_problem orkgr:bioentity_tagging_and_normalization. orkgr:Connecting_the_Persistent_Identifier_Ecosystem_Building_the_Technical_and_Human_Infrastructure_for_Open_Research orkgp:has_research_problem orkgr:Persistent_Identifier_Ecosystem; orkgp:keywords orkgr:Crossref, orkgr:DataCite, orkgr:ORCID_Identifiers, orkgr:connecting_systems, orkgr:metadata, orkgr:persistent_identifier; orkgp:uses_identifier_system orkgr:DOI. orkgr:Contribution_1 orkgp:Best_score \"0.65 micro-F1 for normalized cell type\"^^xsd:string, \"0.76 micro-F1 for normalized species\"^^xsd:string, \"0.8 or better for cell type,  species and gene-or-protein at mention-level F1\"^^xsd:string, \"below 0.6 micro-F1 for other normalized entity types\"^^xsd:string; orkgp:Corpus_genres \"academic abstracts\"^^xsd:string, \"advertisements\"^^xsd:string, \"announcements\"^^xsd:string, \"news\"^^xsd:string; orkgp:Discourse_structure \"constituent tree\"^^xsd:string; orkgp:Evaluation_metrics orkgr:F1, orkgr:Precision, orkgr:Recall; orkgp:Number_of_documents 50; orkgp:Semantic_representation orkgr:RASH; orkgp:description \"The task is to annotate text from figure legends with the entity types and IDs for taxon (organism),  gene,  protein,  miRNA,  small molecules,  cellular components,  cell types and cell lines,  tissues and organs.\"^^xsd:string; orkgp:evaluation \"\"\"Classification Accuracy\"\"\"^^xsd:string, \"User Study \"^^xsd:string; orkgp:number_of_papers \"196 full length articles as test data\"^^xsd:string, \"570 full length articles as training data\"^^xsd:string; orkgp:research_problem orkgr:Semantic_representation_of_scholarly_communication, orkgr:The_need_to_investigate_the_way_to_reduce_academic_researchers_labor_intensive_workload_going_through_all_the_conferences_and_journals_to_find_out_any_scholarly_papers_that_might_relate_to_one_research_topic_searched_by_users_, orkgr:bioentity_tagging_and_normalization. orkgr:Head_Driven_Phrase_Structure_Grammar_Parsing_on_Penn_Treebank orkgp:Benchmark orkgr:Benchmark_CTB5, orkgr:Benchmark_Penn_Treebank; orkgp:research_problem orkgr:Constituency_parsing, orkgr:Dependency_parsing. orkgr:Paper orkgp:description \"A hypothesis is a precise,  testable statement of what the researcher predict will be the outcome of the study.\"^^xsd:string, \"A node shape is a shape that specifies constraint that need to be met with respect to focus nodes.\"^^xsd:string. orkgr:Papers_with_Code orkgp:Semantic_representation \"F\"^^xsd:string; orkgp:Supports_research_data \"T\"^^xsd:string; orkgp:description \"A service from Facebook AI that collects research papers (especially algorithms) in the field of artificial intelligence in a structured way according to the scheme task-metric benchmark and creates rankings from them.\"^^xsd:string; orkgp:research_problem orkgr:Knowledge_representation_for_scholarly_communication. orkgr:Papers_with_code orkgp:Semantic_representation \"F\"^^xsd:string; orkgp:Supports_research_data \"T\"^^xsd:string; orkgp:description \"A service from Facebook AI that collects research papers (especially algorithms) in the field of artificial intelligence in a structured way according to the scheme task-metric benchmark and creates rankings from them.\"^^xsd:string; orkgp:research_problem orkgr:Knowledge_representation_for_scholarly_communication. orkgr:Personalized_Academic_Research_Paper_Recommendation_System orkgp:evaluation \"\"\"Classification Accuracy\"\"\"^^xsd:string, \"User Study \"^^xsd:string; orkgp:research_problem orkgr:The_need_to_investigate_the_way_to_reduce_academic_researchers_labor_intensive_workload_going_through_all_the_conferences_and_journals_to_find_out_any_scholarly_papers_that_might_relate_to_one_research_topic_searched_by_users_. orkgr:Research_Articles_in_Simplified_HTML_a_Web_first_format_for_HTML_based_scholarly_articles orkgp:Semantic_representation orkgr:RASH; orkgp:description \"Covers all aspects of computer graphics\"^^xsd:string; orkgp:research_problem orkgr:Semantic_representation_of_scholarly_communication. orkgr:The_RST_Spanish_Chinese_Treebank orkgp:Corpus_genres \"academic abstracts\"^^xsd:string, \"advertisements\"^^xsd:string, \"announcements\"^^xsd:string, \"news\"^^xsd:string; orkgp:Discourse_structure \"constituent tree\"^^xsd:string; orkgp:Number_of_documents 50. orkgr:Voelker_et_al_2019_ orkgp:Number_of_sentences 189928; orkgp:Number_of_words 3455580; orkgp:research_problem orkgr:Dependency_Treebanking. '"},"metadata":{}}]},{"cell_type":"code","source":"q3 ","metadata":{"execution":{"iopub.status.busy":"2023-10-04T14:12:20.754715Z","iopub.execute_input":"2023-10-04T14:12:20.755118Z","iopub.status.idle":"2023-10-04T14:12:20.760813Z","shell.execute_reply.started":"2023-10-04T14:12:20.755085Z","shell.execute_reply":"2023-10-04T14:12:20.759989Z"},"trusted":true},"execution_count":218,"outputs":[{"execution_count":218,"output_type":"execute_result","data":{"text/plain":"'What models are being evaluated on the UrbanSound8k dataset?'"},"metadata":{}}]},{"cell_type":"code","source":"retrieve_subgraph(q3, orkg)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T14:12:21.578092Z","iopub.execute_input":"2023-10-04T14:12:21.578504Z","iopub.status.idle":"2023-10-04T14:12:21.964836Z","shell.execute_reply.started":"2023-10-04T14:12:21.578471Z","shell.execute_reply":"2023-10-04T14:12:21.963934Z"},"trusted":true},"execution_count":219,"outputs":[{"execution_count":219,"output_type":"execute_result","data":{"text/plain":"'@prefix orkgp: <http://orkg.org/orkg/predicate/>. @prefix orkgr: <http://orkg.org/orkg/resource/>. @prefix xsd: <http://www.w3.org/2001/XMLSchema#>. orkgr:A_Topic_Coverage_Approach_to_Evaluation_of_Topic_Models orkgp:Benchmark orkgr:Benchmark_Topic_modeling_topic_coverage_dataset, orkgr:Benchmark_Topic_modeling_topic_coverage_dataset_bio, orkgr:Benchmark_Topic_modeling_topic_coverage_dataset_news; orkgp:model orkgr:Aucdc, orkgr:Nmf_200, orkgr:Pyp. orkgr:Automatic_Diagnosis_of_Attention_Deficit_Hyperactivity_Disorder_Using_Machine_Learning orkgp:contribution orkgr:Decision_tree, orkgr:K_nearest_Neighbour, orkgr:Naive_Bayes, orkgr:Random_forest, orkgr:Support_vector_machine, orkgr:logistic_regression. orkgr:Contribution_1 orkgp:Capital_enviromental_impact_of_cities_reduction \"no\"^^xsd:string; orkgp:Data_analysis \"No statistical analysis to verify whether the differences in subjective responses were caused by exposure to different indoor conditions\"^^xsd:string; orkgp:Data_processing \"T\"^^xsd:string; orkgp:Has_evaluation_metrics \"PPL\"^^xsd:string; orkgp:Participatory_and_Inclusive_urbanization \"no\"^^xsd:string; orkgp:Results \"Older occupants,  males,  managers or professionals and those with a larger workstation floor area were more satisfied with the lighting than younger occupants,  females,  those holding secretarial or clerical positions and workers with a smaller workplace area even though the former did not have noticeably higher task illuminance\"^^xsd:string; orkgp:Test_data \"\"\"negativepolarity items\"\"\"^^xsd:string, \"reflexive anaphora \"^^xsd:string, \"subject-verb agreement\"^^xsd:string; orkgp:Urban_planning \"no\"^^xsd:string; orkgp:Urban_rural_linkagesages \"no\"^^xsd:string. orkgr:Dynamic_Evaluation_of_Neural_Sequence_Models orkgp:Benchmark orkgr:Benchmark_Hutter_Prize, orkgr:Benchmark_Penn_Treebank_Word_Level_, orkgr:Benchmark_Text8, orkgr:Benchmark_WikiText_2; orkgp:model orkgr:Awd_lstm_dynamic_eval, orkgr:Mlstm_dynamic_eval. orkgr:Evaluating_Large_Language_Models_Trained_on_Code orkgp:Benchmark orkgr:Benchmark_APPS; orkgp:model orkgr:codex_raw_pass_1. orkgr:Model_soups_averaging_weights_of_multiple_fine_tuned_models_improves_accuracy_without_increasing_inference_time orkgp:Benchmark orkgr:Benchmark_ImageNet, orkgr:Benchmark_ImageNet_A, orkgr:Benchmark_ImageNet_R, orkgr:Benchmark_ImageNet_ReaL, orkgr:Benchmark_ImageNet_Sketch, orkgr:Benchmark_ImageNet_V2, orkgr:Benchmark_ObjectNet, orkgr:Quantity_Top_1_Error_Rate_4_54; orkgp:model orkgr:Baseline_vit_g_14, orkgr:Model_soups_vit_g_14. orkgr:On_the_State_of_the_Art_of_Evaluation_in_Neural_Language_Models orkgp:Benchmark orkgr:Benchmark_WikiText_2; orkgp:model orkgr:Melis_et_al_2017_1_layer_lstm_tied. orkgr:Research_Practices orkgp:Data_analysis orkgr:analysis, orkgr:no_analysis. orkgr:Semantic_Answer_Similarity_for_Evaluating_Question_Answering_Models orkgp:has_evaluation_result_others orkgr:Kendall_NQ_open_0_13_0_42_, orkgr:Kendall_on_GermanQuAD_0_33_0_55_, orkgr:Kendall_on_SQuAD_0_29_0_61_, orkgr:Spearman_on_GermanQuAD_0_49_0_68_, orkgr:Spearman_on_NQ_open_0_31_0_54_, orkgr:Spearman_on_SQuAD_0_56_0_75_; orkgp:has_evaluation_tool orkgr:Kendall_correlations_for_F1_0_F1_0_, orkgr:Spearman_correlation_for_F1_0_F1_0_. orkgr:Targeted_Syntactic_Evaluation_of_Language_Models orkgp:Has_evaluation_metrics \"PPL\"^^xsd:string; orkgp:Test_data \"\"\"negativepolarity items\"\"\"^^xsd:string, \"reflexive anaphora \"^^xsd:string, \"subject-verb agreement\"^^xsd:string. '"},"metadata":{}}]},{"cell_type":"code","source":"q4 ","metadata":{"execution":{"iopub.status.busy":"2023-10-04T14:12:23.530530Z","iopub.execute_input":"2023-10-04T14:12:23.530950Z","iopub.status.idle":"2023-10-04T14:12:23.538222Z","shell.execute_reply.started":"2023-10-04T14:12:23.530900Z","shell.execute_reply":"2023-10-04T14:12:23.537273Z"},"trusted":true},"execution_count":220,"outputs":[{"execution_count":220,"output_type":"execute_result","data":{"text/plain":"'Provide a list of research paper titles and IDs that have benchmarked models on the Penn Treebank dataset?'"},"metadata":{}}]},{"cell_type":"code","source":"retrieve_subgraph(q4, orkg)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T14:12:25.000814Z","iopub.execute_input":"2023-10-04T14:12:25.001395Z","iopub.status.idle":"2023-10-04T14:12:26.106947Z","shell.execute_reply.started":"2023-10-04T14:12:25.001347Z","shell.execute_reply":"2023-10-04T14:12:26.106072Z"},"trusted":true},"execution_count":221,"outputs":[{"execution_count":221,"output_type":"execute_result","data":{"text/plain":"'@prefix orkgp: <http://orkg.org/orkg/predicate/>. @prefix orkgr: <http://orkg.org/orkg/resource/>. @prefix xsd: <http://www.w3.org/2001/XMLSchema#>. orkgr:A_benchmarking_method_for_information_systems orkgp:Data_analysis orkgr:analysis; orkgp:Data_collection_method orkgr:case_study, orkgr:study; orkgp:description \"Covers design tools,  software metrics,  testing and debugging,  programming environments,  etc\"^^xsd:string; orkgp:research_paradigm orkgr:exploratory; orkgp:research_problem orkgr:empirical_research_in_requirements_engineering; orkgp:research_question_ orkgr:Research_Questions_in_RE_Contribution; orkgp:research_question_answer orkgr:hidden_in_text. orkgr:Benchmarking_Graph_Neural_Networks orkgp:Benchmark orkgr:Benchmark_CIFAR10_100k, orkgr:Benchmark_CLUSTER, orkgr:Benchmark_COLLAB, orkgr:Benchmark_MNIST, orkgr:Benchmark_PATTERN, orkgr:Benchmark_TSP_HCP_Benchmark_set, orkgr:Benchmark_ZINC_100k, orkgr:Benchmark_ZINC_500k; orkgp:model orkgr:Gatedgcn, orkgr:Gatedgcn_e, orkgr:Gatedgcn_e_pe, orkgr:Gatedgcn_pe; orkgp:research_problem orkgr:Graph_regression, orkgr:Link_prediction. orkgr:CodeXGLUE_A_Machine_Learning_Benchmark_Dataset_for_Code_Understanding_and_Generation orkgp:Benchmark orkgr:Benchmark_CodeXGLUE_AdvTest, orkgr:Benchmark_CodeXGLUE_WebQueryTest; orkgp:model orkgr:Codebert; orkgp:research_problem orkgr:Code_search. orkgr:Developing_Benchmarks_for_Guiding_CAO_Performance orkgp:research_problem orkgr:E_government_competence_. orkgr:E_government_competence_examples orkgp:research_problem orkgr:E_government_competence_. orkgr:Gotta_Go_Fast_When_Generating_Data_with_Score_Based_Models orkgp:Benchmark orkgr:Benchmark_CIFAR_10, orkgr:Benchmark_FFHQ_256_x_256, orkgr:Benchmark_LSUN_Churches_256_x_256; orkgp:model orkgr:Ve_erel_0_01, orkgr:Ve_erel_0_02, orkgr:Ve_new_sde_solver; orkgp:research_problem orkgr:Image_generation. orkgr:Head_Driven_Phrase_Structure_Grammar_Parsing_on_Penn_Treebank orkgp:Benchmark orkgr:Benchmark_CTB5, orkgr:Benchmark_Penn_Treebank; orkgp:model orkgr:Head_driven_phrase_structure_grammar_parsing_joint_bert, orkgr:Head_driven_phrase_structure_grammar_parsing_joint_xlnet, orkgr:Hpsg_parser_joint_xlnet, orkgr:Zhou_etal_2019; orkgp:research_problem orkgr:Constituency_parsing, orkgr:Dependency_parsing. orkgr:Model_soups_averaging_weights_of_multiple_fine_tuned_models_improves_accuracy_without_increasing_inference_time orkgp:Benchmark orkgr:Benchmark_ImageNet, orkgr:Benchmark_ImageNet_A, orkgr:Benchmark_ImageNet_R, orkgr:Benchmark_ImageNet_ReaL, orkgr:Benchmark_ImageNet_Sketch, orkgr:Benchmark_ImageNet_V2, orkgr:Benchmark_ObjectNet, orkgr:Quantity_Top_1_Error_Rate_4_54; orkgp:model orkgr:Baseline_vit_g_14, orkgr:Model_soups_vit_g_14; orkgp:research_problem orkgr:Image_classification, orkgr:Unsupervised_domain_adaptation. orkgr:Paper orkgp:description \"A hypothesis is a precise,  testable statement of what the researcher predict will be the outcome of the study.\"^^xsd:string, \"A node shape is a shape that specifies constraint that need to be met with respect to focus nodes.\"^^xsd:string; orkgp:min_count 1. orkgr:Papers_with_Code orkgp:Metadata \"Partially\"^^xsd:string; orkgp:Supports_research_data \"T\"^^xsd:string; orkgp:description \"A service from Facebook AI that collects research papers (especially algorithms) in the field of artificial intelligence in a structured way according to the scheme task-metric benchmark and creates rankings from them.\"^^xsd:string; orkgp:research_problem orkgr:Knowledge_representation_for_scholarly_communication. orkgr:Profiling_Entity_Matching_Benchmark_Tasks orkgp:Benchmark orkgr:Benchmark_Abt_Buy, orkgr:Benchmark_Amazon_Google, orkgr:Benchmark_WDC_Computers_xlarge; orkgp:model orkgr:Random_forest; orkgp:research_problem orkgr:Entity_resolution. orkgr:Research_Practices orkgp:Data_analysis orkgr:analysis; orkgp:Data_collection_method orkgr:experiment, orkgr:survey; orkgp:research_paradigm orkgr:exploratory; orkgp:research_problem orkgr:empirical_research_in_requirements_engineering; orkgp:research_question_ orkgr:Research_Questions_in_RE_Contribution; orkgp:research_question_answer orkgr:hidden_in_text. orkgr:Softcite orkgp:Results orkgr:result1, orkgr:result2, orkgr:result3, orkgr:result4, orkgr:result5; orkgp:curated true; orkgp:curated_by \"Expert annotators\"^^xsd:string; orkgp:data_source orkgr:PubMed_Central, orkgr:Unpaywall; orkgp:description \"We created the Softcite dataset,  which is presented as a TEI/XML file with paragraphs from articles automatically converted from PDF publications,  as well as article level metadata. In these paragraphs are annotations of 4, 093 software mentions,  together with 2, 541 annotations of their details including publisher,  version,  and URL.\"^^xsd:string; orkgp:model orkgr:CRF_based_NER; orkgp:name \"Softcite\"^^xsd:string; orkgp:research_problem orkgr:Named_entity_recognition. orkgr:Voelker_et_al_2019_ orkgp:research_problem orkgr:Dependency_Treebanking. '"},"metadata":{}}]},{"cell_type":"code","source":"q5","metadata":{"execution":{"iopub.status.busy":"2023-10-04T14:12:29.243223Z","iopub.execute_input":"2023-10-04T14:12:29.244401Z","iopub.status.idle":"2023-10-04T14:12:29.249055Z","shell.execute_reply.started":"2023-10-04T14:12:29.244344Z","shell.execute_reply":"2023-10-04T14:12:29.248376Z"},"trusted":true},"execution_count":222,"outputs":[{"execution_count":222,"output_type":"execute_result","data":{"text/plain":"'What models are being evaluated on the TDMSci dataset?'"},"metadata":{}}]},{"cell_type":"code","source":"retrieve_subgraph(q5, orkg)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T14:12:30.202516Z","iopub.execute_input":"2023-10-04T14:12:30.203193Z","iopub.status.idle":"2023-10-04T14:12:30.591981Z","shell.execute_reply.started":"2023-10-04T14:12:30.203161Z","shell.execute_reply":"2023-10-04T14:12:30.590875Z"},"trusted":true},"execution_count":223,"outputs":[{"execution_count":223,"output_type":"execute_result","data":{"text/plain":"'@prefix orkgp: <http://orkg.org/orkg/predicate/>. @prefix orkgr: <http://orkg.org/orkg/resource/>. @prefix xsd: <http://www.w3.org/2001/XMLSchema#>. orkgr:A_Topic_Coverage_Approach_to_Evaluation_of_Topic_Models orkgp:Benchmark orkgr:Benchmark_Topic_modeling_topic_coverage_dataset, orkgr:Benchmark_Topic_modeling_topic_coverage_dataset_bio, orkgr:Benchmark_Topic_modeling_topic_coverage_dataset_news; orkgp:model orkgr:Aucdc, orkgr:Nmf_200, orkgr:Pyp. orkgr:Contribution_1 orkgp:Has_evaluation_metrics \"PPL\"^^xsd:string; orkgp:Test_Data_Languages \"English\"^^xsd:string; orkgp:Test_data \"\"\"negativepolarity items\"\"\"^^xsd:string, \"reflexive anaphora \"^^xsd:string, \"subject-verb agreement\"^^xsd:string; orkgp:Training_data \"Wikipedia\"^^xsd:string; orkgp:evaluation orkgr:Task_Dataset_Metric_Score. orkgr:Dynamic_Evaluation_of_Neural_Sequence_Models orkgp:Benchmark orkgr:Benchmark_Hutter_Prize, orkgr:Benchmark_Penn_Treebank_Word_Level_, orkgr:Benchmark_Text8, orkgr:Benchmark_WikiText_2; orkgp:model orkgr:Awd_lstm_dynamic_eval, orkgr:Mlstm_dynamic_eval. orkgr:Evaluating_Large_Language_Models_Trained_on_Code orkgp:Benchmark orkgr:Benchmark_APPS; orkgp:model orkgr:codex_raw_pass_1. orkgr:Gotta_Go_Fast_When_Generating_Data_with_Score_Based_Models orkgp:Benchmark orkgr:Benchmark_CIFAR_10, orkgr:Benchmark_FFHQ_256_x_256, orkgr:Benchmark_LSUN_Churches_256_x_256; orkgp:model orkgr:Ve_erel_0_01, orkgr:Ve_erel_0_02, orkgr:Ve_new_sde_solver. orkgr:Improved_Precision_and_Recall_Metric_for_Assessing_Generative_Models orkgp:Benchmark orkgr:Benchmark_FFHQ; orkgp:model orkgr:Stylegan_no_instance_norm. orkgr:Model_soups_averaging_weights_of_multiple_fine_tuned_models_improves_accuracy_without_increasing_inference_time orkgp:Benchmark orkgr:Benchmark_ImageNet, orkgr:Benchmark_ImageNet_A, orkgr:Benchmark_ImageNet_R, orkgr:Benchmark_ImageNet_ReaL, orkgr:Benchmark_ImageNet_Sketch, orkgr:Benchmark_ImageNet_V2, orkgr:Benchmark_ObjectNet, orkgr:Quantity_Top_1_Error_Rate_4_54; orkgp:model orkgr:Baseline_vit_g_14, orkgr:Model_soups_vit_g_14. orkgr:On_the_State_of_the_Art_of_Evaluation_in_Neural_Language_Models orkgp:Benchmark orkgr:Benchmark_WikiText_2; orkgp:model orkgr:Melis_et_al_2017_1_layer_lstm_tied. orkgr:Research_Practices orkgp:Data_analysis orkgr:analysis, orkgr:no_analysis. orkgr:Semantic_Answer_Similarity_for_Evaluating_Question_Answering_Models orkgp:has_evaluation_result_others orkgr:Kendall_NQ_open_0_13_0_42_, orkgr:Kendall_on_GermanQuAD_0_33_0_55_, orkgr:Kendall_on_SQuAD_0_29_0_61_, orkgr:Spearman_on_GermanQuAD_0_49_0_68_, orkgr:Spearman_on_NQ_open_0_31_0_54_, orkgr:Spearman_on_SQuAD_0_56_0_75_; orkgp:has_evaluation_tool orkgr:Kendall_correlations_for_F1_0_F1_0_, orkgr:Spearman_correlation_for_F1_0_F1_0_. orkgr:Targeted_Syntactic_Evaluation_of_Language_Models orkgp:Has_evaluation_metrics \"PPL\"^^xsd:string; orkgp:Test_Data_Languages \"English\"^^xsd:string; orkgp:Test_data \"\"\"negativepolarity items\"\"\"^^xsd:string, \"reflexive anaphora \"^^xsd:string, \"subject-verb agreement\"^^xsd:string; orkgp:Training_data \"Wikipedia\"^^xsd:string. '"},"metadata":{}}]},{"cell_type":"code","source":"import json\nwith open(\"/kaggle/input/sciqa-dataset/SciQA-dataset/test/questions.json\", 'rb') as f:\n    test_file = f.read()\n\nwith open(\"/kaggle/input/sciqa-dataset/SciQA-dataset/train/questions.json\", 'rb') as f:\n    train_file = f.read()    \n\nwith open(\"/kaggle/input/sciqa-dataset/SciQA-dataset/valid/questions.json\", 'rb') as f:\n    valid_file = f.read()  \n\ntest = json.loads(test_file)\ntrain = json.loads(train_file)\nvalid = json.loads(valid_file)\n\ntest_q = test['questions']\ntrain_q = train['questions']\nvalid_q = valid['questions']","metadata":{"execution":{"iopub.status.busy":"2023-10-04T12:14:00.030471Z","iopub.execute_input":"2023-10-04T12:14:00.031476Z","iopub.status.idle":"2023-10-04T12:14:00.073677Z","shell.execute_reply.started":"2023-10-04T12:14:00.031435Z","shell.execute_reply":"2023-10-04T12:14:00.072746Z"},"trusted":true},"execution_count":133,"outputs":[]},{"cell_type":"code","source":"from transformers import GPT2Tokenizer\ntokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n\ndef measure_num_tokens(datasets:list, tokenizer):\n    res = []\n    for dataset in datasets:\n        for q in dataset:\n            out = retrieve_subgraph(q['question']['string'], orkg)\n            tokens = tokenizer(out)[\"input_ids\"]\n            res.append(len(tokens))  \n    return pd.DataFrame(res)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T13:06:46.174059Z","iopub.execute_input":"2023-10-04T13:06:46.174490Z","iopub.status.idle":"2023-10-04T13:06:46.180546Z","shell.execute_reply.started":"2023-10-04T13:06:46.174459Z","shell.execute_reply":"2023-10-04T13:06:46.179592Z"},"trusted":true},"execution_count":197,"outputs":[]},{"cell_type":"code","source":"measure_num_tokens([test_q, train_q, valid_q], tokenizer)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T13:11:02.770165Z","iopub.execute_input":"2023-10-04T13:11:02.770523Z","iopub.status.idle":"2023-10-04T13:47:11.398577Z","shell.execute_reply.started":"2023-10-04T13:11:02.770497Z","shell.execute_reply":"2023-10-04T13:47:11.397712Z"},"trusted":true},"execution_count":200,"outputs":[{"execution_count":200,"output_type":"execute_result","data":{"text/plain":"                  0\ncount   2565.000000\nmean    1871.264327\nstd     1359.458444\nmin        0.000000\n25%     1115.000000\n50%     1528.000000\n75%     1906.000000\nmax    17454.000000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>2565.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>1871.264327</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1359.458444</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>1115.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1528.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1906.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>17454.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def aug_dataset(dataset):\n    res = []\n    for q in dataset:\n        out = retrieve_subgraph(q['question']['string'], orkg)\n        res.append(out) \n    return res\n\ndef write_json(dataset, filename):\n    with open(filename) as file: \n        file_data = json.load(file)\n    subgraphs = aug_dataset(dataset)\n    for idx, q in enumerate(file_data['questions']):\n        q['subgraph'] = subgraphs[idx]\n    return file_data\n#     with open(filename,'r+') as file:  \n#         json.dump(file_data, file, indent = 4)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T14:51:56.623883Z","iopub.execute_input":"2023-10-04T14:51:56.624341Z","iopub.status.idle":"2023-10-04T14:51:56.630811Z","shell.execute_reply.started":"2023-10-04T14:51:56.624307Z","shell.execute_reply":"2023-10-04T14:51:56.629911Z"},"trusted":true},"execution_count":271,"outputs":[]}]}