{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%pip install -U sentence-transformers\n%pip install hnswlib\n%pip install SPARQLWrapper\n%pip install rdflib\n%pip install spacy\n# python -m spacy download en_core_web_sm","metadata":{"execution":{"iopub.status.busy":"2023-10-04T06:21:28.281307Z","iopub.execute_input":"2023-10-04T06:21:28.281662Z","iopub.status.idle":"2023-10-04T06:22:57.641851Z","shell.execute_reply.started":"2023-10-04T06:21:28.281636Z","shell.execute_reply":"2023-10-04T06:22:57.640370Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport sys\nimport hnswlib\nimport pickle\nimport rdflib\nimport SPARQLWrapper\nimport numpy as np\nimport pandas as pd\nimport spacy\nfrom io import StringIO\nfrom rdflib import Graph\nfrom SPARQLWrapper import SPARQLWrapper, JSON, RDF, XML \nfrom sentence_transformers import SentenceTransformer, util\n\nmodel = SentenceTransformer('all-MiniLM-L12-v2')\nnlp = spacy.load(\"en_core_web_sm\")\nstopwords = nlp.Defaults.stop_words\n\ndata_path = os.getcwd()+'\\\\data'","metadata":{"execution":{"iopub.status.busy":"2023-10-04T06:28:13.797865Z","iopub.execute_input":"2023-10-04T06:28:13.798320Z","iopub.status.idle":"2023-10-04T06:28:48.928765Z","shell.execute_reply.started":"2023-10-04T06:28:13.798234Z","shell.execute_reply":"2023-10-04T06:28:48.927430Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open(os.path.join(data_path, 'id2pred.pickle'), \"rb\") as input_file:\n    id2pred = pickle.load(input_file) \n    \nwith open(os.path.join(data_path, 'pred2id.pickle'), \"rb\") as input_file:\n    pred2id = pickle.load(input_file)    \n    \nwith open(os.path.join(data_path, 'pred2emb.pickle'), \"rb\") as input_file:\n    pred2emb = pickle.load(input_file)  \n\nwith open(os.path.join(data_path, 'id2res.pickle'), \"rb\") as input_file:\n    id2res = pickle.load(input_file)\n    \n# with open(os.path.join(data_path, 'res2id.pickle'), \"rb\") as input_file:\n#     res2id = pickle.load(input_file)    \n\n# with open(os.path.join(data_path, 'res2emb.pickle'), \"rb\") as input_file:   \n#     res2emb = pickle.load(input_file)\n\nwith open(os.path.join(data_path, 'contrib2emb.pickle'), \"rb\") as input_file: \n    contrib2emb = pickle.load(input_file) \n\nwith open(os.path.join(data_path, 'contrib2id.pickle'), \"rb\") as input_file: \n    contrib2id = pickle.load(input_file)\n\nwith open(os.path.join(data_path, 'contrib2emb.pickle'), \"rb\") as input_file:    \n    contrib2emb = pickle.load(input_file)    \n    \n      \nwith open(os.path.join(data_path, 'id2paper.pickle'), \"rb\") as input_file:     \n    id2paper = pickle.load(input_file)\n    \nwith open(os.path.join(data_path, 'paper2id.pickle'), \"rb\") as input_file: \n    paper2id = pickle.load(input_file)    \n    \nwith open(os.path.join(data_path, 'paper2emb.pickle'), \"rb\") as input_file:    \n    paper2emb = pickle.load(input_file)\n    \n\nwith open(os.path.join(data_path, 'pred_index.pickle'), \"rb\") as input_file:     \n    pred_index = pickle.load(input_file) \n\n# with open(os.path.join(data_path, 'res_index.pickle'), \"rb\") as input_file:    \n#     res_index = pickle.load(input_file)  \n\nwith open(os.path.join(data_path, 'contrib_index.pickle'), \"rb\") as input_file:    \n    contrib_index = pickle.load(input_file)     \n\nwith open(os.path.join(data_path, 'paper_index.pickle'), \"rb\") as input_file: \n    paper_index = pickle.load(input_file)    ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def filter_q(question:str):\n    \"\"\"\n    filter out unnecessary words from a question\n    \"\"\"\n    res = []\n    tok_pos = []\n    for token in nlp(question):\n        tok_pos.append((token.lemma_, token.pos_))\n        if token.pos_ in [\"NOUN\", \"PROPN\", \"ADJ\", \"VERB\"]: # keep only nouns, adjectives and verbs\n            if token.lemma_ not in stopwords:\n                res.append(str(token))\n    return \" \".join(res)\n\ndef create_n_grams(sentence, n=2):\n    \"\"\"\n    create n_grams for a sentence after its filtering\n    \"\"\"\n    filtered_sentence = filter_q(sentence)\n    words = filtered_sentence.split(\" \")\n    n_grams = []\n    text_l = len(words)\n    for i in range(2, n+1):\n        for j in range(text_l-i):\n            n_gram = words[j:j+i]\n            n_gram_text = \" \".join(n_gram)\n            n_grams.append(n_gram_text)\n    return n_grams\n\ndef set_prefixes(graph, prefixes=[]):\n    \"\"\"\n    set all prefixes from a list for a graph\n    \"\"\"\n    for prefix in prefixes:\n        graph.bind(prefix[0], prefix[1])","metadata":{"execution":{"iopub.status.busy":"2023-10-04T06:29:02.171420Z","iopub.execute_input":"2023-10-04T06:29:02.171819Z","iopub.status.idle":"2023-10-04T06:29:02.180654Z","shell.execute_reply.started":"2023-10-04T06:29:02.171775Z","shell.execute_reply":"2023-10-04T06:29:02.179531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def n_closest(question, source, n, n_gram):\n    \"\"\"\n    return n elements of orkg relevant for a question\n    \"\"\"\n    if n_gram:\n        filteted_text = filter_q(question)\n        texts = create_n_grams(filteted_text)\n    else:\n        texts = [filter_q(question)]\n    if source==\"pred\":\n        tuples = []\n        for text in texts:\n            out, scores = pred_index.knn_query(model.encode(text, show_progress_bar=False), k=n)\n            tuples.extend(list(zip(out[0], scores[0])))\n        sorted_out = sort_tuples(tuples)[0:n]\n        all_preds = list(pred2emb.keys())\n        output = [all_preds[pair[0]] for pair in sorted_out]\n        return output\n    elif source==\"res\":\n        tuples = []\n        for text in texts:\n            out, scores = res_index.knn_query(model.encode(text, show_progress_bar=False), k=n)\n            tuples.extend(list(zip(out[0], scores[0])))\n        sorted_out = sort_tuples(tuples)[0:n]\n        all_res = list(res2emb.keys())\n        output = [all_res[pair[0]] for pair in sorted_out]\n        return output\n    elif source==\"paper\":\n        tuples = []\n        for text in texts:\n            out, scores = paper_index.knn_query(model.encode(text, show_progress_bar=False), k=n)\n            tuples.extend(list(zip(out[0], scores[0])))\n        sorted_out = sort_tuples(tuples)[0:n]\n        all_papers = list(paper2emb.keys())\n        papers = [all_papers[pair[0]] for pair in sorted_out]\n        output = [str(uri) for uri in papers]\n        return output\n    elif source==\"contrib\":\n        tuples = []\n        for text in texts:\n            out, scores = contrib_index.knn_query(model.encode(text, show_progress_bar=False), k=n)\n            tuples.extend(list(zip(out[0], scores[0])))\n        sorted_out = sort_tuples(tuples)[0:n]\n        all_contribs = list(contrib2emb.keys())\n        contribs = [all_contribs[pair[0]] for pair in sorted_out]\n        output = [str(uri) for uri in contribs]\n        return output\n    \ndef sort_tuples(l):\n    out = []\n    black_list = []\n    tuples = sorted(l, key=lambda x: x[1], reverse=False)\n    for tup in tuples:\n        if tup[0] in black_list:\n            continue\n        else:\n            out.append(tup)\n            black_list.append(tup[0])\n    return out","metadata":{"execution":{"iopub.status.busy":"2023-10-04T07:07:22.352925Z","iopub.execute_input":"2023-10-04T07:07:22.353461Z","iopub.status.idle":"2023-10-04T07:07:22.374128Z","shell.execute_reply.started":"2023-10-04T07:07:22.353406Z","shell.execute_reply":"2023-10-04T07:07:22.373368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def construct_subgraph(triples=[], predicates_list=[]):\n    \"\"\"\n    return a graph for a list of triples\n    \"\"\"\n    res_graph = Graph()\n    set_prefixes(res_graph, prefixes)\n    for ind, triple in enumerate(triples):\n        pred_id = str(triple[1]).split(\"/\")[-1]\n        try:\n            pred = id2pred[pred_id]\n        except Exception as e:\n            continue\n        if pred not in predicates_list:\n            continue\n        else:\n            text_triple = swap_prefixes(triple)\n            res_graph.add(text_triple) \n    return res_graph\n\ndef get_subgraph_string(graph):\n    \"\"\"\n    return string representation of a graph\n    \"\"\"\n    tmp = sys.stdout\n    my_result = StringIO()\n    sys.stdout = my_result\n    graph.print()\n    sys.stdout = tmp\n    return my_result.getvalue()\n\ndef swap_prefixes(triple):\n    \"\"\"\n    replace ids in a triple with textual representation\n    \"\"\"\n    subj_id = str(triple[0]).split(\"/\")[-1]\n    subj_base = str(triple[0]).split(\"/\")[0:-1]\n    if subj_id in id2res.keys():\n        subj = id2res[subj_id].replace(\" \", \"_\").replace(\":\", \"_\")\n        subj_base.append(subj)\n        triple[0] = rdflib.term.URIRef(\"/\".join(subj_base))\n    \n    pred_id = str(triple[1]).split(\"/\")[-1]\n    pred_base = str(triple[1]).split(\"/\")[0:-1]\n    if pred_id in id2pred.keys():\n        pred = id2pred[pred_id].replace(\" \", \"_\").replace(\":\", \"_\")\n        pred_base.append(pred)\n        triple[1] = rdflib.term.URIRef(\"/\".join(pred_base))\n    \n    obj_id = str(triple[2]).split(\"/\")[-1]\n    obj_base = str(triple[2]).split(\"/\")[0:-1]\n    if obj_id in id2res.keys():\n        obj = id2res[obj_id].replace(\" \", \"_\").replace(\":\", \"_\")\n        obj_base.append(obj)\n        triple[2] = rdflib.term.URIRef(\"/\".join(obj_base))\n    return triple    ","metadata":{"execution":{"iopub.status.busy":"2023-10-04T07:13:24.359651Z","iopub.execute_input":"2023-10-04T07:13:24.359992Z","iopub.status.idle":"2023-10-04T07:13:24.371596Z","shell.execute_reply.started":"2023-10-04T07:13:24.359965Z","shell.execute_reply":"2023-10-04T07:13:24.370695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def process_paper(paper_title, predicates_list, graph):\n    \"\"\"\n    return a subgraph of orkg for a paper using only relevant predicates\n    \"\"\"\n    paper_id = paper2id[paper_title]\n    left = '{'\n    right = '}'\n    middle = f'orkgr:{paper_id} ?x ?y. ?y ?pred ?label'\n    template = f'PREFIX orkgp: <http://orkg.org/orkg/predicate/> PREFIX orkgc: <http://orkg.org/orkg/class/> PREFIX orkgr: <http://orkg.org/orkg/resource/> SELECT ?pred ?label WHERE {left}{middle}{right}'\n    result = graph.query(template)\n    triples = []\n    for triple in result:\n        triples.append([rdflib.term.URIRef(f'http://orkg.org/orkg/resource/{paper_id }'), triple[0], triple[1]])\n    graph = construct_subgraph(triples, predicates_list)\n    return graph\n\ndef process_contrib(contrib_title, predicates_list, graph):\n    \"\"\"\n    return a subgraph of orkg for a contribution using only relevant predicates\n    \"\"\"\n    contrib_id = contrib2id[contrib_title]\n    left = '{'\n    right = '}'\n    middle = f'orkgr:{contrib_id} ?x ?y'\n    template = f'PREFIX orkgp: <http://orkg.org/orkg/predicate/> PREFIX orkgc: <http://orkg.org/orkg/class/> PREFIX orkgr: <http://orkg.org/orkg/resource/> SELECT ?x ?y WHERE {left}{middle}{right}'\n    result = graph.query(template)\n    triples = []\n    for triple in result:\n        triples.append([rdflib.term.URIRef(f'http://orkg.org/orkg/resource/{contrib_id }'), triple[0], triple[1]])\n    graph = construct_subgraph(triples, predicates_list)\n    return graph\n\ndef graph_text_postprocessing(graph_text:str):\n    \"\"\"\n    postprocess to improve graph serialization\n    \"\"\"\n    postprocessed_graph = graph_text.replace(\"\\n\", \"\").replace(\"  \", \"\").replace(\" .\", \". \").replace(\" ;\", \"; \") \n    return postprocessed_graph","metadata":{"execution":{"iopub.status.busy":"2023-10-04T07:10:19.262797Z","iopub.execute_input":"2023-10-04T07:10:19.263209Z","iopub.status.idle":"2023-10-04T07:10:19.273249Z","shell.execute_reply.started":"2023-10-04T07:10:19.263178Z","shell.execute_reply":"2023-10-04T07:10:19.272090Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"orkg = Graph()\norkg.parse(os.path.join(data_path, 'rdf-export-orkg.nt'))\nprefixes = [\n['orkgp', 'http://orkg.org/orkg/predicate/'],\n['orkgc', 'http://orkg.org/orkg/class/'],\n['orkgr', 'http://orkg.org/orkg/resource/'],\n['rdfs', 'http://www.w3.org/2000/01/rdf-schema#>'],\n['rdf', 'http://www.w3.org/1999/02/22-rdf-syntax-ns#'],\n['xsd', 'http://www.w3.org/2001/XMLSchema#']   \n]\nset_prefixes(g, prefixes)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T06:31:26.461604Z","iopub.execute_input":"2023-10-04T06:31:26.461965Z","iopub.status.idle":"2023-10-04T06:32:22.157673Z","shell.execute_reply.started":"2023-10-04T06:31:26.461937Z","shell.execute_reply":"2023-10-04T06:32:22.156570Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def retrieve_subgraph(question:str, main_graph:rdflib.Graph, n_preds:int=1000, n_papers:int=10, n_contribs:int=10):\n    \"\"\"\n    return a number of orkg subrgraphs related to a question\n    \"\"\"\n    subgraphs = []\n    predicates_list = n_closest(question, 'pred', n_preds, True)\n    papers_list = n_closest(question, 'paper', n_papers, True)\n    contribs_list = n_closest(question, 'contrib', n_contribs, True)\n    for paper in papers_list:\n        graph = process_paper(paper, predicates_list, main_graph)\n        if len(graph) > 0:\n            graph_text = get_subgraph_string(graph) \n            graph_text_postprocessed = graph_text_postprocessing(graph_text)\n            subgraphs.append(graph_text_postprocessed) \n    for contrib in contribs_list:\n        graph = process_contrib(contrib, predicates_list, main_graph)\n        if len(graph) > 0:\n            graph_text = get_subgraph_string(graph) \n            graph_text_postprocessed = graph_text_postprocessing(graph_text)\n            subgraphs.append(graph_text_postprocessed) \n    return subgraphs","metadata":{"execution":{"iopub.status.busy":"2023-10-04T07:11:49.671260Z","iopub.execute_input":"2023-10-04T07:11:49.672437Z","iopub.status.idle":"2023-10-04T07:11:49.679518Z","shell.execute_reply.started":"2023-10-04T07:11:49.672396Z","shell.execute_reply":"2023-10-04T07:11:49.678635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"q1 = \"Which model has achieved the highest Accuracy score on the Story Cloze Test benchmark dataset?\"\nq2 = \"List the title and ID of research papers that contain a benchmark over the Penn Treebank (Word Level) dataset?\"\nq3 = \"What models are being evaluated on the UrbanSound8k dataset?\"\nq4 = \"Provide a list of research paper titles and IDs that have benchmarked models on the Penn Treebank dataset?\"\nq5 = \"What models are being evaluated on the TDMSci dataset?\"\nq6 = \"What is the mean capacity of a carbon-based fuel?\"\nq7 = \"Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the MLDoc Zero-Shot English-to-Russian dataset?\"\nq8 = \"Indicate the model that performed best in terms of Accuracy metric on the Kuzushiji-MNIST benchmark dataset?\"\nq9 = \"Which model has achieved the highest BLEU score score on the WMT2016 Romanian-English benchmark dataset?\"\nq10 = \"What is the highest benchmark result achieved on the Ball in cup, catch (DMControl500k) dataset, including the metric and its value?\"","metadata":{"execution":{"iopub.status.busy":"2023-10-04T07:15:21.169411Z","iopub.execute_input":"2023-10-04T07:15:21.170282Z","iopub.status.idle":"2023-10-04T07:15:21.175387Z","shell.execute_reply.started":"2023-10-04T07:15:21.170210Z","shell.execute_reply":"2023-10-04T07:15:21.174482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"retrieve_subgraph(q1, orkg)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T07:11:59.933770Z","iopub.execute_input":"2023-10-04T07:11:59.934220Z","iopub.status.idle":"2023-10-04T07:12:00.883806Z","shell.execute_reply.started":"2023-10-04T07:11:59.934187Z","shell.execute_reply":"2023-10-04T07:12:00.883008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"q2","metadata":{"execution":{"iopub.status.busy":"2023-10-04T07:15:26.856727Z","iopub.execute_input":"2023-10-04T07:15:26.857130Z","iopub.status.idle":"2023-10-04T07:15:26.862777Z","shell.execute_reply.started":"2023-10-04T07:15:26.857099Z","shell.execute_reply":"2023-10-04T07:15:26.861700Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"retrieve_subgraph(q2, orkg)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T07:12:09.619128Z","iopub.execute_input":"2023-10-04T07:12:09.619518Z","iopub.status.idle":"2023-10-04T07:12:10.775030Z","shell.execute_reply.started":"2023-10-04T07:12:09.619487Z","shell.execute_reply":"2023-10-04T07:12:10.774439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"q3","metadata":{"execution":{"iopub.status.busy":"2023-10-04T07:15:05.050218Z","iopub.execute_input":"2023-10-04T07:15:05.050635Z","iopub.status.idle":"2023-10-04T07:15:05.056205Z","shell.execute_reply.started":"2023-10-04T07:15:05.050599Z","shell.execute_reply":"2023-10-04T07:15:05.055341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"retrieve_subgraph(q3, orkg)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T07:14:52.450364Z","iopub.execute_input":"2023-10-04T07:14:52.451593Z","iopub.status.idle":"2023-10-04T07:14:52.829568Z","shell.execute_reply.started":"2023-10-04T07:14:52.451549Z","shell.execute_reply":"2023-10-04T07:14:52.828801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"q4","metadata":{"execution":{"iopub.status.busy":"2023-10-04T07:15:47.842121Z","iopub.execute_input":"2023-10-04T07:15:47.842489Z","iopub.status.idle":"2023-10-04T07:15:47.847701Z","shell.execute_reply.started":"2023-10-04T07:15:47.842461Z","shell.execute_reply":"2023-10-04T07:15:47.846913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"retrieve_subgraph(q4, orkg)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T07:15:42.236417Z","iopub.execute_input":"2023-10-04T07:15:42.236784Z","iopub.status.idle":"2023-10-04T07:15:43.340511Z","shell.execute_reply.started":"2023-10-04T07:15:42.236756Z","shell.execute_reply":"2023-10-04T07:15:43.339729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"q5","metadata":{"execution":{"iopub.status.busy":"2023-10-04T07:15:53.595939Z","iopub.execute_input":"2023-10-04T07:15:53.596574Z","iopub.status.idle":"2023-10-04T07:15:53.603360Z","shell.execute_reply.started":"2023-10-04T07:15:53.596527Z","shell.execute_reply":"2023-10-04T07:15:53.602405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"retrieve_subgraph(q5, orkg)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T07:15:59.962268Z","iopub.execute_input":"2023-10-04T07:15:59.962950Z","iopub.status.idle":"2023-10-04T07:16:00.324035Z","shell.execute_reply.started":"2023-10-04T07:15:59.962904Z","shell.execute_reply":"2023-10-04T07:16:00.323392Z"},"trusted":true},"execution_count":null,"outputs":[]}]}